# streamlit_app/pages/06_ğŸ§ª_verificacion_reto.py
"""
ğŸ§ª VERIFICACIÃ“N DEL RETO
=======================
PÃ¡gina dedicada para mostrar la comprobaciÃ³n de resultados del punto 3:
â— EstadÃ­sticas en ejecuciÃ³n
â— Consultas directas a BD
â— ComparaciÃ³n antes/despuÃ©s de validation.csv
"""

import streamlit as st
import pandas as pd
import sqlite3
import json
from pathlib import Path
import sys
from datetime import datetime

# Configurar paths
PROJECT_ROOT = Path(__file__).parent.parent.parent
SRC_PATH = PROJECT_ROOT / "src"
sys.path.insert(0, str(SRC_PATH))

st.set_page_config(page_title="VerificaciÃ³n del Reto", page_icon="ğŸ§ª", layout="wide")

def main():
    st.title("ğŸ§ª VerificaciÃ³n del Reto - ComprobaciÃ³n de Resultados")
    st.markdown("**Cumplimiento del Punto 3: ComprobaciÃ³n de resultados**")
    
    # Verificar si hay datos para mostrar
    if not check_data_availability():
        st.warning("âš ï¸ No hay datos procesados. Ejecuta el pipeline primero.")
        if st.button("ğŸš€ Ir a Control del Pipeline"):
            st.switch_page("pages/02_ğŸš€_pipeline_control.py")
        return
    
    # Crear tabs para cada verificaciÃ³n
    tab1, tab2, tab3, tab4 = st.tabs([
        "ğŸ“Š EstadÃ­sticas en EjecuciÃ³n",
        "ğŸ—„ï¸ Consulta BD Directa", 
        "ğŸ§ª Validation.csv",
        "ğŸ“ˆ ComparaciÃ³n Final"
    ])
    
    with tab1:
        show_running_statistics()
    
    with tab2:
        show_database_query()
    
    with tab3:
        show_validation_processing()
    
    with tab4:
        show_final_comparison()

def check_data_availability():
    """Verifica si hay datos disponibles para mostrar"""
    db_path = PROJECT_ROOT / "data" / "pipeline.db"
    return db_path.exists()

def show_running_statistics():
    """Muestra las estadÃ­sticas en ejecuciÃ³n (Punto 3.1)"""
    st.markdown("### ğŸ“Š EstadÃ­sticas en EjecuciÃ³n")
    st.markdown("**Requerimiento**: *Imprime el valor actual de las estadÃ­sticas en ejecuciÃ³n*")
    
    # Cargar estadÃ­sticas incrementales
    stats_data = load_incremental_statistics()
    
    if stats_data:
        st.success("âœ… EstadÃ­sticas incrementales disponibles")
        
        # Mostrar en formato de mÃ©tricas grandes
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric(
                label="ğŸ“ˆ Total de Registros",
                value=f"{stats_data.get('count', 0):,}",
                help="Contador incremental - NO recalculado desde BD"
            )
        
        with col2:
            st.metric(
                label="ğŸ’° Precio Promedio",
                value=f"${stats_data.get('avg', 0):.2f}",
                help="Promedio calculado incrementalmente"
            )
        
        with col3:
            st.metric(
                label="ğŸ“‰ Precio MÃ­nimo", 
                value=f"${stats_data.get('min', 0):.2f}",
                help="MÃ­nimo encontrado durante procesamiento"
            )
        
        with col4:
            st.metric(
                label="ğŸ“ˆ Precio MÃ¡ximo",
                value=f"${stats_data.get('max', 0):.2f}",
                help="MÃ¡ximo encontrado durante procesamiento"
            )
        
        # InformaciÃ³n adicional
        st.markdown("#### ğŸ“‹ Detalles de las EstadÃ­sticas Incrementales")
        
        details_col1, details_col2 = st.columns(2)
        
        with details_col1:
            st.info(f"""
            **ğŸ’ Suma Total**: ${stats_data.get('sum', 0):,.2f}
            **ğŸ• Ãšltima ActualizaciÃ³n**: {stats_data.get('last_updated', 'N/A')}
            **ğŸ“¦ Batches Procesados**: {stats_data.get('batches_processed', 'N/A')}
            """)
        
        with details_col2:
            st.success(f"""
            **âš¡ Eficiencia**: O(1) por operaciÃ³n
            **ğŸ”„ MÃ©todo**: EstadÃ­sticas incrementales
            **âœ… Ventaja**: NO recalcula desde base de datos
            """)
        
        # Mostrar datos raw en JSON expandible
        with st.expander("ğŸ” Ver datos completos de estadÃ­sticas incrementales"):
            st.json(stats_data)
    
    else:
        st.error("âŒ No se encontraron estadÃ­sticas incrementales")
        st.info("Las estadÃ­sticas se generan durante la ejecuciÃ³n del pipeline")

def show_database_query():
    """Muestra consulta directa a la base de datos (Punto 3.2)"""
    st.markdown("### ğŸ—„ï¸ Consulta Directa a Base de Datos")
    st.markdown("**Requerimiento**: *Consulta en la base de datos del: recuento total, promedio, mÃ­nimo y mÃ¡ximo*")
    
    try:
        db_path = PROJECT_ROOT / "data" / "pipeline.db"
        
        if not db_path.exists():
            st.error("âŒ Base de datos no encontrada")
            return
        
        # Ejecutar consulta directa
        conn = sqlite3.connect(str(db_path))
        
        query = """
        SELECT 
            COUNT(*) as total_records,
            AVG(price) as average_price,
            MIN(price) as minimum_price,
            MAX(price) as maximum_price,
            SUM(price) as total_sum,
            COUNT(DISTINCT user_id) as unique_users,
            COUNT(DISTINCT source_file) as unique_files
        FROM transactions
        """
        
        cursor = conn.execute(query)
        result = cursor.fetchone()
        conn.close()
        
        if result and result[0] > 0:
            st.success("âœ… Consulta a base de datos ejecutada exitosamente")
            
            # Mostrar resultados de la consulta
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric(
                    label="ğŸ—„ï¸ Registros en BD",
                    value=f"{result[0]:,}",
                    help="COUNT(*) directo desde base de datos"
                )
            
            with col2:
                st.metric(
                    label="ğŸ’° Promedio BD",
                    value=f"${result[1]:.2f}" if result[1] else "$0.00",
                    help="AVG(price) calculado por SQL"
                )
            
            with col3:
                st.metric(
                    label="ğŸ“‰ MÃ­nimo BD", 
                    value=f"${result[2]:.2f}" if result[2] else "$0.00",
                    help="MIN(price) desde base de datos"
                )
            
            with col4:
                st.metric(
                    label="ğŸ“ˆ MÃ¡ximo BD",
                    value=f"${result[3]:.2f}" if result[3] else "$0.00",
                    help="MAX(price) desde base de datos"
                )
            
            # InformaciÃ³n adicional de BD
            st.markdown("#### ğŸ“Š InformaciÃ³n Adicional de Base de Datos")
            
            col_extra1, col_extra2, col_extra3 = st.columns(3)
            
            with col_extra1:
                st.info(f"**ğŸ’ Suma Total BD**: ${result[4]:,.2f}" if result[4] else "$0.00")
            
            with col_extra2:
                st.info(f"**ğŸ‘¥ Usuarios Ãšnicos**: {result[5]:,}")
            
            with col_extra3:
                st.info(f"**ğŸ“„ Archivos Procesados**: {result[6]}")
            
            # Mostrar la consulta SQL ejecutada
            with st.expander("ğŸ” Ver consulta SQL ejecutada"):
                st.code(query, language="sql")
            
            # Comparar con estadÃ­sticas incrementales
            show_statistics_comparison()
        
        else:
            st.warning("âš ï¸ No hay datos en la base de datos")
    
    except Exception as e:
        st.error(f"âŒ Error ejecutando consulta: {str(e)}")

def show_validation_processing():
    """Muestra el procesamiento de validation.csv (Punto 3.3)"""
    st.markdown("### ğŸ§ª Procesamiento de Validation.csv")
    st.markdown("**Requerimiento**: *Ejecuta validation.csv y muestra estadÃ­sticas en ejecuciÃ³n*")
    
    # Verificar si validation fue procesado
    validation_status = check_validation_processed()
    
    if validation_status['processed']:
        st.success("âœ… Validation.csv fue procesado exitosamente")
        
        # Mostrar estadÃ­sticas antes de validation
        if validation_status['before_stats']:
            st.markdown("#### ğŸ“Š EstadÃ­sticas ANTES de procesar validation.csv")
            
            before_stats = validation_status['before_stats']
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric("Count", f"{before_stats.get('count', 0):,}")
            with col2:
                st.metric("Promedio", f"${before_stats.get('avg', 0):.2f}")
            with col3:
                st.metric("MÃ­nimo", f"${before_stats.get('min', 0):.2f}")
            with col4:
                st.metric("MÃ¡ximo", f"${before_stats.get('max', 0):.2f}")
        
        # Mostrar estadÃ­sticas despuÃ©s de validation
        if validation_status['after_stats']:
            st.markdown("#### ğŸ“ˆ EstadÃ­sticas DESPUÃ‰S de procesar validation.csv")
            
            after_stats = validation_status['after_stats']
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric("Count", f"{after_stats.get('count', 0):,}")
            with col2:
                st.metric("Promedio", f"${after_stats.get('avg', 0):.2f}")
            with col3:
                st.metric("MÃ­nimo", f"${after_stats.get('min', 0):.2f}")
            with col4:
                st.metric("MÃ¡ximo", f"${after_stats.get('max', 0):.2f}")
        
        # Mostrar cambios detectados
        if validation_status['changes']:
            st.markdown("#### ğŸ”„ Cambios Detectados por Validation.csv")
            changes = validation_status['changes']
            
            change_col1, change_col2, change_col3 = st.columns(3)
            
            with change_col1:
                st.metric(
                    "Filas AÃ±adidas",
                    f"+{changes.get('count_added', 0):,}",
                    delta=f"+{changes.get('count_added', 0)}"
                )
            
            with change_col2:
                st.metric(
                    "Cambio en Promedio",
                    f"${changes.get('avg_after', 0):.2f}",
                    delta=f"{changes.get('avg_change', 0):+.2f}"
                )
            
            with change_col3:
                if changes.get('new_min') or changes.get('new_max'):
                    st.success("ğŸ”„ Nuevos valores min/max detectados")
                else:
                    st.info("ğŸ“Š Rango de precios sin cambios")
    
    else:
        st.warning("âš ï¸ Validation.csv aÃºn no ha sido procesado")
        st.info("El archivo validation.csv se procesa automÃ¡ticamente al final del pipeline")
        
        if st.button("ğŸš€ Ejecutar Pipeline Completo"):
            st.switch_page("pages/02_ğŸš€_pipeline_control.py")

def show_final_comparison():
    """Muestra comparaciÃ³n final BD vs EstadÃ­sticas (Punto 3.4)"""
    st.markdown("### ğŸ“ˆ ComparaciÃ³n Final: EstadÃ­sticas vs Base de Datos")
    st.markdown("**Requerimiento**: *Nueva consulta BD despuÃ©s de validation.csv*")
    
    # Obtener estadÃ­sticas incrementales
    incremental_stats = load_incremental_statistics()
    
    # Obtener estadÃ­sticas de BD
    db_stats = get_database_statistics()
    
    if incremental_stats and db_stats:
        st.success("âœ… ComparaciÃ³n disponible")
        
        # Tabla de comparaciÃ³n
        comparison_data = {
            "MÃ©trica": ["Count", "Promedio", "MÃ­nimo", "MÃ¡ximo"],
            "EstadÃ­sticas Incrementales": [
                f"{incremental_stats.get('count', 0):,}",
                f"${incremental_stats.get('avg', 0):.2f}",
                f"${incremental_stats.get('min', 0):.2f}",
                f"${incremental_stats.get('max', 0):.2f}"
            ],
            "Consulta BD Directa": [
                f"{db_stats.get('count', 0):,}",
                f"${db_stats.get('avg', 0):.2f}",
                f"${db_stats.get('min', 0):.2f}",
                f"${db_stats.get('max', 0):.2f}"
            ],
            "Â¿Coinciden?": []
        }
        
        # Verificar coincidencias
        tolerance = 1e-6
        
        matches = [
            "âœ…" if incremental_stats.get('count', 0) == db_stats.get('count', 0) else "âŒ",
            "âœ…" if abs(incremental_stats.get('avg', 0) - db_stats.get('avg', 0)) < tolerance else "âŒ",
            "âœ…" if abs(incremental_stats.get('min', 0) - db_stats.get('min', 0)) < tolerance else "âŒ",
            "âœ…" if abs(incremental_stats.get('max', 0) - db_stats.get('max', 0)) < tolerance else "âŒ"
        ]
        
        comparison_data["Â¿Coinciden?"] = matches
        
        # Mostrar tabla de comparaciÃ³n
        df_comparison = pd.DataFrame(comparison_data)
        st.dataframe(df_comparison, use_container_width=True)
        
        # VerificaciÃ³n general
        all_match = all("âœ…" in match for match in matches)
        
        if all_match:
            st.success("ğŸ‰ Â¡VERIFICACIÃ“N EXITOSA! Las estadÃ­sticas incrementales coinciden exactamente con la consulta directa a BD")
            st.balloons()
        else:
            st.error("âŒ Hay diferencias entre las estadÃ­sticas incrementales y la BD")
        
        # Mostrar ventajas del mÃ©todo incremental
        st.markdown("#### âš¡ Ventajas del MÃ©todo Incremental")
        
        col_advantage1, col_advantage2 = st.columns(2)
        
        with col_advantage1:
            st.info("""
            **ğŸš€ Eficiencia:**
            - O(1) por operaciÃ³n
            - No recalcula desde BD
            - Escalable a millones de registros
            """)
        
        with col_advantage2:
            st.success("""
            **âœ… PrecisiÃ³n:**
            - Mismos resultados que SQL
            - Actualizaciones en tiempo real
            - VerificaciÃ³n automÃ¡tica
            """)
    
    else:
        st.error("âŒ No se pueden comparar - faltan datos")

def load_incremental_statistics():
    """Carga estadÃ­sticas incrementales"""
    try:
        stats_path = PROJECT_ROOT / "data" / "processed" / "pipeline_statistics.json"
        if stats_path.exists():
            with open(stats_path, 'r') as f:
                data = json.load(f)
                return data.get('stats', {})
        return {}
    except:
        return {}

def get_database_statistics():
    """Obtiene estadÃ­sticas directas de BD"""
    try:
        db_path = PROJECT_ROOT / "data" / "pipeline.db"
        if not db_path.exists():
            return {}
        
        conn = sqlite3.connect(str(db_path))
        cursor = conn.execute("""
            SELECT 
                COUNT(*) as count,
                AVG(price) as avg,
                MIN(price) as min,
                MAX(price) as max
            FROM transactions
        """)
        result = cursor.fetchone()
        conn.close()
        
        if result and result[0] > 0:
            return {
                'count': result[0],
                'avg': float(result[1]) if result[1] else 0.0,
                'min': float(result[2]) if result[2] else 0.0,
                'max': float(result[3]) if result[3] else 0.0
            }
        
        return {}
    except:
        return {}

def show_statistics_comparison():
    """Muestra comparaciÃ³n entre estadÃ­sticas incrementales y BD"""
    st.markdown("#### ğŸ” ComparaciÃ³n: Incremental vs BD")
    
    incremental = load_incremental_statistics()
    db_stats = get_database_statistics()
    
    if incremental and db_stats:
        # Verificar coincidencias
        count_match = incremental.get('count', 0) == db_stats.get('count', 0)
        avg_match = abs(incremental.get('avg', 0) - db_stats.get('avg', 0)) < 1e-6
        min_match = abs(incremental.get('min', 0) - db_stats.get('min', 0)) < 1e-6
        max_match = abs(incremental.get('max', 0) - db_stats.get('max', 0)) < 1e-6
        
        if count_match and avg_match and min_match and max_match:
            st.success("âœ… Las estadÃ­sticas incrementales coinciden exactamente con la BD")
        else:
            st.warning("âš ï¸ Hay pequeÃ±as diferencias (revisar tolerancia)")

def check_validation_processed():
    """Verifica si validation fue procesado y obtiene estadÃ­sticas antes/despuÃ©s"""
    try:
        stats_path = PROJECT_ROOT / "data" / "processed" / "pipeline_statistics.json"
        if stats_path.exists():
            with open(stats_path, 'r') as f:
                data = json.load(f)
                
                # Buscar evidencia de validation procesado
                processed = 'validation_stats' in data or data.get('stats', {}).get('count', 0) > 0
                
                return {
                    'processed': processed,
                    'before_stats': data.get('before_validation', {}),
                    'after_stats': data.get('after_validation', data.get('stats', {})),
                    'changes': data.get('validation_changes', {})
                }
        
        return {'processed': False, 'before_stats': {}, 'after_stats': {}, 'changes': {}}
    except:
        return {'processed': False, 'before_stats': {}, 'after_stats': {}, 'changes': {}}

if __name__ == "__main__":
    main()